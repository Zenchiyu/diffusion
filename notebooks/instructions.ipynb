{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8581e5a7-67a8-4662-9ccf-ca931463663c",
   "metadata": {},
   "source": [
    "**Miniproject 1: Image generation with a diffusion model**\n",
    "\n",
    "The goal of this miniproject is to build a diffusion model from scratch to generate images.\n",
    "\n",
    "There are many flavors of diffusion models. Here, we will take inspiration from *Elucidating the Design Space of Diffusion-Based Generative Models*, a paper by Tero Karras, Miika Aittala, Timo Aila, Samuli Laine, presented at NeurIPS 2022, available [here](https://openreview.net/pdf?id=k7FuTOWMOc7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb88c2e-f325-49e8-866b-315cb14803f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527714fe-bfbe-4993-bdcf-df28cba2b10f",
   "metadata": {},
   "source": [
    "# Background on diffusion models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f6f78-2127-493f-b07b-d2e99669adbd",
   "metadata": {},
   "source": [
    "We have the following two processes:\n",
    "\n",
    "- **Noising process**: start from clean images, add noise until it is indistinguishable from pure noise.\n",
    "- **Denoising process**: start from pure noise, iteratively denoiser until it looks like an actual image from the data distribution.\n",
    "\n",
    "The first one is straightforward, as we just have to degrade images. The second one is much more difficult, and our goal will be to train a neural network to achieve it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c67a3d-6748-4885-923c-ad3207757dbe",
   "metadata": {},
   "source": [
    "## Noising process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354ef50-460c-4b40-b0d4-f7e8661e0b48",
   "metadata": {},
   "source": [
    "We can gradually degrade an image with a sequence of increasing noise levels $\\sigma_0 = 0 < \\sigma_1 < \\dots < \\sigma_T = \\sigma_{max}$, in a way that the last step is indistinguishable from pure noise.\n",
    "\n",
    "![Noising process](images/noising.png)\n",
    "\n",
    "**Algorithm 1: Noising procedure**\n",
    "> - Sample an image $y \\sim p_{data}$ (i.e. from the dataset)\n",
    "> - Sample a noise level $\\sigma \\sim p_{noise}$\n",
    "> - Sample gaussian noise $\\epsilon \\sim \\mathcal{N}(0, I)$\n",
    "> - Obtain degraded sample $x$ by adding noise to the image, $x = y + \\sigma \\epsilon$\n",
    "\n",
    "**Important**: This is how you will have to degrade clean images during training. \n",
    "\n",
    "Notes:\n",
    "\n",
    "- $p_{data}$ is unknown, but we have access to samples from the dataset.\n",
    "- We will design a good $p_{noise}$ later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fd5b06-e053-4256-84f9-5bbd32d2ffad",
   "metadata": {},
   "source": [
    "## Denoising objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa0137-d733-4517-9155-2b54d98806ac",
   "metadata": {},
   "source": [
    "We are looking for a denoising function $D$ that returns the clean image given the noised image $D(x, \\sigma) = y $. Note that $D$ is also taking the noise level $\\sigma$.\n",
    "\n",
    "We will thus *train* a parametric function $D_\\theta$ with parameters $\\theta$, with the following denoising MSE loss,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\theta) = \\mathbb{E}_{y,\\sigma,\\epsilon} \\Big[ \\| D_\\theta(y + \\sigma \\epsilon, \\sigma) - y \\|^2 \\; \\Big] \n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $y \\sim p_{data}, \\sigma \\sim p_{noise}, \\epsilon \\sim \\mathcal{N}(0, I)$ are sampled as described in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d6e7b-a322-410b-8091-211d137ae116",
   "metadata": {},
   "source": [
    "## Parameterization and actual loss for the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e9e399-d6e7-4c81-8ad3-864274e3f895",
   "metadata": {},
   "source": [
    "We could directly parameterize $D_\\theta$ with a neural network, but this would pose several practical issues (details in the paper). Instead, Karras et al. propose the following parameterization of $D_\\theta$,\n",
    "\n",
    "$$\n",
    "D_\\theta(x, \\sigma) = c_{skip}(\\sigma) \\; x + c_{out}(\\sigma) \\; F_\\theta(c_{in}(\\sigma)\\;x, c_{noise}(\\sigma))\n",
    "$$\n",
    "\n",
    "Where **$F_\\theta$ is the neural network we want to train**. We will define $c_{in},c_{out},c_{skip},c_{noise}$ in the next section, you can ignore them for the moment.\n",
    "\n",
    "Injecting this parameterization in the denoising loss, we obtain the actual training loss for the network $F_\\theta$,\n",
    "$$\n",
    "\\mathcal{L}(\\theta)  = \\mathbb{E}_{y,\\epsilon,\\sigma} \\Big[ \\; \\Vert \n",
    "\\underbrace{F_\\theta \\big( c_\\text{in}(\\sigma) \\; (y + \\sigma\\epsilon), c_{noise}(\\sigma) \\big)}_\\text{Neural network prediction} -\n",
    "\\underbrace{\\frac{1}{c_\\text{out}(\\sigma)} \\big( y - c_{skip}(\\sigma) \\; (y+\\sigma\\epsilon) \\big) }_\\text{Neural network training target}\n",
    "\\Vert^2 \\; \\Big].\n",
    "$$\n",
    "\n",
    "**Important**: The left-most term is the output of our neural network, and the right-most term is the training target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982598d-8644-44a6-958e-f7db350c47ba",
   "metadata": {},
   "source": [
    "## Defining $c_{in},c_{out},c_{skip},c_{noise}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c65e7f-abd2-4918-a379-06ee349c6fd8",
   "metadata": {},
   "source": [
    "We remark that $c_{in},c_{out},c_{skip},c_{noise}$ are only function of the noise level $\\sigma$, and we note that,\n",
    "\n",
    "- $c_{in}(\\sigma)$ scales the network input\n",
    "- $c_{out}(\\sigma)$ scales the network output\n",
    "- $c_{skip}(\\sigma)$ controls the skip connection\n",
    "- $c_{noise}(\\sigma)$ transforms the noise level before giving it to the network.\n",
    "\n",
    "In order to solve the practical issues mentioned above, we define them as follow,\n",
    "\n",
    "$$\n",
    "c_{in}(\\sigma) = \\frac{1}{\\sqrt{\\sigma_{data}^2 \\; + \\; \\sigma^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "c_{out}(\\sigma) = \\frac{\\sigma.\\sigma_{data}}{\\sqrt{\\sigma^2 + \\sigma_{data}^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "c_{skip}(\\sigma) = \\frac{\\sigma_{data}^2}{\\sigma_{data}^2 + \\sigma^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "c_{noise}(\\sigma) = ln(\\sigma)/4\n",
    "$$\n",
    "\n",
    "Where we denote $\\sigma_{data}$ the standard deviation of the data distribution. This constant can be estimated from the dataset, and is returned by the `load_dataset_and_make_dataloaders` function described above.\n",
    "\n",
    "Intuitively,\n",
    "\n",
    "- $c_{in}$ is chosen to have unit-variance input to the network.\n",
    "- $c_{out}$ is chosen to have unit-variance target for the network.\n",
    "- $c_{skip}$ adapts the networks's target depending on the noise level, $\\sigma$. When $\\sigma \\gg \\sigma_\\text{data}$, we have, $c_\\text{skip}(\\sigma) \\approx 0$, and the training target for $F_\\theta$ is dominated by the clean signal, $y$. Conversely, when the noise level is low, $\\sigma \\approx 0$, we have, $c_\\text{skip}(\\sigma) \\approx 1$, and the target is dominated by the noise, $\\epsilon$. This approach yields a robust training objective that makes sure the network is never asked to perform a trivial task.        \n",
    "- $c_{noise}$ is chosen empirically in the paper.\n",
    "\n",
    "**Important**: You will need to implement these 4 functions of $\\sigma$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9a478-7469-4312-8ea8-d32806e98689",
   "metadata": {},
   "source": [
    "## Defining $p_{noise}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c49066-c77b-407d-8274-099189cb8a50",
   "metadata": {},
   "source": [
    "Following the paper, we will sample $\\sigma$ with a log-normal distribution during training,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382f529-0187-4662-9a68-03fbe01d6f93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_sigma(n, loc=-1.2, scale=1.2, sigma_min=2e-3, sigma_max=80):\n",
    "    return (torch.randn(n) * scale + loc).exp().clip(sigma_min, sigma_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc6b9a-7dd4-4162-b2b6-dbca40619638",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "You can plot an histrogram of values of $\\sigma$ and verify they are indeed following a log-normal distribution,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a52a59-629c-4cda-90f5-16b33e9b5dbe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "sigma = sample_sigma(1000)\n",
    "\n",
    "plt.subplot(211)\n",
    "hist, bins, _ = plt.hist(sigma.tolist(), bins=100)\n",
    "\n",
    "plt.subplot(212)\n",
    "logbins = torch.logspace(math.log(bins[0]), math.log(bins[-1]), steps=len(bins))\n",
    "plt.hist(sigma.tolist(), bins=logbins)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538e9ec-d150-4ec3-8087-e2ffa6771e28",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df06731-a4c1-4233-9343-435d160d898a",
   "metadata": {},
   "source": [
    "### Technical / formal remark (see the paper for details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd5152-1cd7-475c-8d88-ab721e13841e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "When sampling, we are actually solving the following differential equation \n",
    "\n",
    "$$\n",
    "dx = -\\sigma \\nabla_x \\log p(x, \\sigma) d\\sigma\n",
    "$$\n",
    "\n",
    "where $\\nabla_x \\log p(x, \\sigma)$ is also known as the \"score\" function. This score function is thus the object we want to estimate from the beginning, without telling it. There is a formal link between the optimal denoiser $D$ and the score function,\n",
    "\n",
    "$$\n",
    "\\nabla_x \\log p(x, \\sigma) = \\frac{D(x, \\sigma) - x}{\\sigma^2}\n",
    "$$\n",
    "\n",
    "This link is why we constructed a way to estimate D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca871a-98a9-4815-b7c0-9856d3746ceb",
   "metadata": {},
   "source": [
    "### Defining a discrete schedule of sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6848a9f0-5dc7-4745-9d6d-3405e32605cb",
   "metadata": {},
   "source": [
    "To sample a new image, we have to define a sequence of noise levels $\\sigma_T = \\sigma_{max} > \\dots > \\sigma_1 > \\sigma_0 = 0$. \n",
    "\n",
    "While a simple linear interpolation between $\\sigma_{max}$ and $0$ would work, Karras et al. empirically found better schedules, and you can use it with the function `build_sigma_schedule` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7406ae-bc29-4fe3-a706-e557f7f17e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sigma_schedule(steps, rho=7, sigma_min=2e-3, sigma_max=80):\n",
    "    min_inv_rho = sigma_min ** (1 / rho)\n",
    "    max_inv_rho = sigma_max ** (1 / rho)\n",
    "    sigmas = (max_inv_rho + torch.linspace(0, 1, steps) * (min_inv_rho - max_inv_rho)) ** rho\n",
    "    return sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c978bbfd-88c7-47c6-b940-892fa34b8285",
   "metadata": {},
   "source": [
    "You can visualize the effect of `rho` with the cell below. `rho=7` is the default suggested in the paper, `rho=1` is the linear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61771e1-7ce0-4bc4-885f-85b225001899",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rho in range(1, 10):\n",
    "    sigmas = build_sigma_schedule(steps=50, sigma_min=2e-3, sigma_max=80, rho=rho)\n",
    "    plt.plot(sigmas.tolist(), label=f'rho={rho}')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae06686-4dc3-4dd9-917d-b18a6bba14ec",
   "metadata": {},
   "source": [
    "### A simple sampling algorithm (Euler's method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca91c796-f065-46b2-8610-d2e462fa80a0",
   "metadata": {},
   "source": [
    "While the paper introduces second order sampling method, we will keep a simple approach here and use Euler's method, implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd74ee-b6e2-4438-b027-4d69b3cae789",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = lambda x, sigma: x  # dummy D, just for the cell below to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39add107-91e7-4caf-8660-e197eef174b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = build_sigma_schedule(steps=50, rho=7)  # Sequence of decreasing sigmas\n",
    "\n",
    "x = torch.randn(8, 1, 32, 32) * sigmas[0]  # Initialize with pure gaussian noise ~ N(0, sigmas[0])\n",
    "\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        x_denoised = D(x, sigma)  \n",
    "        # Where D(x, sigma) = cskip(sigma) * x + cout(sigma) * F(cin(sigma) * x, cnoise(sigma)) \n",
    "        # and F(.,.) is your neural network\n",
    "    \n",
    "    sigma_next = sigmas[i + 1] if i < len(sigmas) - 1 else 0\n",
    "    d = (x - x_denoised) / sigma\n",
    "    \n",
    "    x = x + d * (sigma_next - sigma)  # Perform one step of Euler's method\n",
    "\n",
    "# -> Final `x` contains the sampled images (8 here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a874ce9c-6130-4a08-b45f-fb73f94a7abf",
   "metadata": {},
   "source": [
    "You can take inspiration from the following code to plot the obtained images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fe258-e4e6-4896-9d10-006d046220e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "x = x.clamp(-1, 1).add(1).div(2).mul(255).byte()  # [-1., 1.] -> [0., 1.] -> [0, 255]\n",
    "x = make_grid(x)\n",
    "x = Image.fromarray(x.permute(1, 2, 0).cpu().numpy())\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdcb303-577b-4912-aba2-66953e5433af",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf0e863-e338-4391-9319-fbacf17c338b",
   "metadata": {},
   "source": [
    "The main goal of the project is to **build a complete training + sampling pipeline**.\n",
    "\n",
    "We provide here a possible sketch of the project. Also, we provide in the next sections helpers for data loading and some building blocks for a UNet.\n",
    "\n",
    "**Advised step 1: Build the training pipeline**\n",
    "\n",
    "Here is a summary of the main steps for the training procedure,\n",
    "\n",
    ">- Sample an image `y` from the dataset\n",
    ">- Sample `sigma` from $p_{noise}$\n",
    ">- Create a noisy image `x` by adding gaussian noise of std `sigma` to the clean image `y`\n",
    ">- Compute `cin`, `cout`, `cskip` and `cnoise`\n",
    ">- Forward pass: your network should take two inputs, `cin * x` and `cnoise`, and should output a tensor of the same size as `x`\n",
    ">- Compute MSE loss with `target = (y - cskip * x) / cout`\n",
    "\n",
    "Also, we advise to\n",
    "\n",
    "- Start with FashionMNIST.\n",
    "- Start with the model provided in `model.py`.\n",
    "- Use batches and a GPU if you can (on google colab for instance).\n",
    "\n",
    "**Advised step 2: Build the sampling pipeline**\n",
    "\n",
    "Here is a summary of the sampling procedure,\n",
    "\n",
    ">- Create a sequence of decreasing `sigmas` using `build_sigma_schedule`\n",
    ">- Sample initial gaussian noise of standard deviation `sigmas[0]`\n",
    ">- To obtain an image, apply iteratively your denoising network, following Euler's method described in the background section \n",
    "\n",
    "- At this stage, you should obtain images that look like FashionMNIST, but are quite bad.\n",
    "- You can make nice visualizations of the iterative denoising process. \n",
    "\n",
    "**Advised step 3: Improve architecture**\n",
    "\n",
    "The model provided in `model.py` is not conditioned on the noise level! \n",
    "\n",
    "For now, the `c_noise` argument goes into the provided `NoiseEmbedding` layer (projection on random directions), whose output is then not plugged to anything.\n",
    "\n",
    "- Find a way to plug this quantity in the model. You can try the first simple approaches that come to your mind.\n",
    "- Otherwise, a simple (and very effective) approach is to code a **conditional** BatchNorm2d mechanism, where you train a linear layer to map the condition (the noise level here) to the affine parameters of the batch norm. To that end, you should modify the default behavior of `nn.BatchNorm2d` by setting `affine=False` (deactivate learnable parameters of the module), and **add your own linear layer, to predict the affine parameters given the noise embedding**.\n",
    "- This should give you much better images (barely distinguishable from real images).\n",
    "- Evaluate your generated images with FID to have a quantive measure of the improvement.\n",
    "- You can also improve on the initialization of your model, for instance by initializing the weights of `conv2` (in residual blocks) and `conv_out` to zero.\n",
    "\n",
    "THIS IS ALREADY A GOOD PROJECT AT THIS STAGE! \n",
    "\n",
    "**Suggested next steps**\n",
    "\n",
    "*Idea 1: class-conditioning*\n",
    "\n",
    "- How can you ask for a specific class?\n",
    "- Once you have that, you can even play with Classifier-Free Guidance.   \n",
    "\n",
    "*Idea 2: other dataset, for instance CelebA (face generation)*\n",
    "\n",
    "*Idea 3: try and improve the architecture*\n",
    "\n",
    "*Feel free to do anything else you find interesting.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b18bb-5c43-4b5f-9044-99645dd93f13",
   "metadata": {},
   "source": [
    "# Data helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ff386-a3b8-4c4f-b71b-15b835b31103",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We will mostly work with FashionMNIST (and optionally CelebA). Feel free to use more datasets if you want.\n",
    "\n",
    "| Dataset | Number of images | Split train / valid | Image size | Image range | Preprocessing |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| FashionMNIST | 60k | 50k / 10k | 32 x 32 | [-1, 1] | Pad the original 28 x 28 to 32 x 32 |\n",
    "| CelebA | 162770 | 150k / 12770 | 128 x 128 | [-1, 1] | Center-crop the original 178 x 218 to 178 x 178 then rescale to 128 x 128 |\n",
    "\n",
    "This preprocessing is already implemented for you. You can use the function `load_dataset_and_make_dataloaders` from the file `data.py` as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b19029-656e-4ccf-9b20-16732e636672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_dataset_and_make_dataloaders\n",
    "\n",
    "gpu = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if gpu else 'cpu')\n",
    " \n",
    "dl, info = load_dataset_and_make_dataloaders(\n",
    "    dataset_name='FashionMNIST',\n",
    "    root_dir='data', # choose the directory to store the data \n",
    "    batch_size=32,\n",
    "    num_workers=0,   # you can use more workers if you see the GPU is waiting for the batches\n",
    "    pin_memory=gpu,  # use pin memory if you're planning to move the data to GPU\n",
    ")\n",
    "\n",
    "print(info)\n",
    "\n",
    "for x, y in dl.train:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9046c057-53e4-43f7-96b2-d028d70aec53",
   "metadata": {},
   "source": [
    "## Error loading CelebA\n",
    "\n",
    "You might get an error when downloading CelebA.\n",
    "\n",
    "You can try and download [here](https://drive.google.com/drive/folders/0B7EVK8r0v71pWEZsZE9oNnFzTm8) the following files and place them in your `root_dir/celeba` (with `root_dir` being the directory you pass to the function above).\n",
    "\n",
    "- *img_align_celeba.zip*\n",
    "- *list_attr_celeba.txt*\n",
    "- *identity_CelebA.txt*\n",
    "- *list_bbox_celeba.txt*\n",
    "- *list_landmarks_align_celeba.txt*\n",
    "- *list_eval_partition.txt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96663e86-6822-48c4-8e11-9ef0ee2083d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
